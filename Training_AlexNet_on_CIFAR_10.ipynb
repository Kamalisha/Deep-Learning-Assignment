{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPhaTTCGD0q3IrBGDwMqzUc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kamalisha/Deep-Learning-Assignment/blob/main/Training_AlexNet_on_CIFAR_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvwM-RcO1VTR"
      },
      "outputs": [],
      "source": [
        "#Training AlexNet on CIFAR-10 to achieve high accuracy in classifying 10 different classes of images."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision import models\n",
        "\n",
        "from sklearn import decomposition\n",
        "from sklearn import manifold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tqdm.notebook import tqdm, trange\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import copy\n",
        "import random\n",
        "import time\n"
      ],
      "metadata": {
        "id": "_CAxuqSc1ZYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "rORkRYJa1pzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = '.data'\n",
        "\n",
        "train_data = datasets.CIFAR10(root=ROOT,\n",
        "                              train=True,\n",
        "                              download=True)\n",
        "\n",
        "means = train_data.data.mean(axis=(0, 1, 2)) / 255\n",
        "stds = train_data.data.std(axis=(0, 1, 2)) / 255\n",
        "\n",
        "print(f'Calculated means: {means}')\n",
        "print(f'Calculated stds: {stds}')"
      ],
      "metadata": {
        "id": "WkeKzH377I3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = transforms.Compose([\n",
        "                           transforms.RandomRotation(5),\n",
        "                           transforms.RandomHorizontalFlip(0.5),\n",
        "                           transforms.RandomCrop(32, padding=2),\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=means,\n",
        "                                                std=stds)\n",
        "                       ])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Normalize(mean=means,\n",
        "                                                std=stds)\n",
        "                       ])"
      ],
      "metadata": {
        "id": "elwx7LVI7PL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.CIFAR10(ROOT,\n",
        "                              train=True,\n",
        "                              download=True,\n",
        "                              transform=train_transforms)\n",
        "\n",
        "test_data = datasets.CIFAR10(ROOT,\n",
        "                             train=False,\n",
        "                             download=True,\n",
        "                             transform=test_transforms)"
      ],
      "metadata": {
        "id": "fusE8ZxK7TPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VALID_RATIO = 0.9\n",
        "\n",
        "n_train_examples = int(len(train_data) * VALID_RATIO)\n",
        "n_valid_examples = len(train_data) - n_train_examples\n",
        "\n",
        "train_data, valid_data = data.random_split(train_data,\n",
        "                                           [n_train_examples, n_valid_examples])"
      ],
      "metadata": {
        "id": "xdR2HvNm7bgR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_data = copy.deepcopy(valid_data)\n",
        "valid_data.dataset.transform = test_transforms"
      ],
      "metadata": {
        "id": "BCndnOU97bVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Number of training examples: {len(train_data)}')\n",
        "print(f'Number of validation examples: {len(valid_data)}')\n",
        "print(f'Number of testing examples: {len(test_data)}')"
      ],
      "metadata": {
        "id": "Nmm-0VjO7f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_images(images, labels, classes, normalize=False):\n",
        "\n",
        "    n_images = len(images)\n",
        "\n",
        "    rows = int(np.sqrt(n_images))\n",
        "    cols = int(np.sqrt(n_images))\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    for i in range(rows*cols):\n",
        "\n",
        "        ax = fig.add_subplot(rows, cols, i+1)\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image_min = image.min()\n",
        "            image_max = image.max()\n",
        "            image.clamp_(min=image_min, max=image_max)\n",
        "            image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "\n",
        "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
        "        ax.set_title(classes[labels[i]])\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "jRZ34R-x7j3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_IMAGES = 25\n",
        "\n",
        "images, labels = zip(*[(image, label) for image, label in\n",
        "                       [train_data[i] for i in range(N_IMAGES)]])\n",
        "\n",
        "classes = test_data.classes\n",
        "\n",
        "plot_images(images, labels, classes)"
      ],
      "metadata": {
        "id": "737KEImD7n9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_images(images, labels, classes, normalize=True)"
      ],
      "metadata": {
        "id": "82vk2pcT7rNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(image):\n",
        "    image_min = image.min()\n",
        "    image_max = image.max()\n",
        "    image.clamp_(min=image_min, max=image_max)\n",
        "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "clqgXVGD-Xhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_filter(images, filter, normalize=True):\n",
        "\n",
        "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
        "    filter = torch.FloatTensor(filter).unsqueeze(0).unsqueeze(0).cpu()\n",
        "    filter = filter.repeat(3, 3, 1, 1)\n",
        "\n",
        "    n_images = images.shape[0]\n",
        "\n",
        "    filtered_images = F.conv2d(images, filter)\n",
        "\n",
        "    images = images.permute(0, 2, 3, 1)\n",
        "    filtered_images = filtered_images.permute(0, 2, 3, 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(25, 5))\n",
        "\n",
        "    for i in range(n_images):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(2, n_images, i+1)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title('Original')\n",
        "        ax.axis('off')\n",
        "\n",
        "        image = filtered_images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(2, n_images, n_images+i+1)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title('Filtered')\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "FLuTRfSM-eHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_IMAGES = 10\n",
        "\n",
        "images = [image for image, label in [train_data[i] for i in range(N_IMAGES)]]\n",
        "\n",
        "horizontal_filter = [[-1, -2, -1],\n",
        "                     [ 0,  0,  0],\n",
        "                     [ 1,  2,  1]]\n",
        "\n",
        "plot_filter(images, horizontal_filter)"
      ],
      "metadata": {
        "id": "nD_A8GFjEo3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertical_filter = [[-1, 0, 1],\n",
        "                   [-2, 0, 2],\n",
        "                   [-1, 0, 1]]\n",
        "\n",
        "plot_filter(images, vertical_filter)\n"
      ],
      "metadata": {
        "id": "M2H92arrEu5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_subsample(images, pool_type, pool_size, normalize=True):\n",
        "\n",
        "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
        "\n",
        "    if pool_type.lower() == 'max':\n",
        "        pool = F.max_pool2d\n",
        "    elif pool_type.lower() in ['mean', 'avg']:\n",
        "        pool = F.avg_pool2d\n",
        "    else:\n",
        "        raise ValueError(f'pool_type must be either max or mean, got: {pool_type}')\n",
        "\n",
        "    n_images = images.shape[0]\n",
        "\n",
        "    pooled_images = pool(images, kernel_size=pool_size)\n",
        "\n",
        "    images = images.permute(0, 2, 3, 1)\n",
        "    pooled_images = pooled_images.permute(0, 2, 3, 1)\n",
        "\n",
        "    fig = plt.figure(figsize=(25, 5))\n",
        "\n",
        "    for i in range(n_images):\n",
        "\n",
        "        image = images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(2, n_images, i+1)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title('Original')\n",
        "        ax.axis('off')\n",
        "\n",
        "        image = pooled_images[i]\n",
        "\n",
        "        if normalize:\n",
        "            image = normalize_image(image)\n",
        "\n",
        "        ax = fig.add_subplot(2, n_images, n_images+i+1)\n",
        "        ax.imshow(image)\n",
        "        ax.set_title('Subsampled')\n",
        "        ax.axis('off')"
      ],
      "metadata": {
        "id": "5RQGNDL7EzVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_subsample(images, 'max', 2)"
      ],
      "metadata": {
        "id": "VvSYuyeQ-jIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_subsample(images, 'max', 3)"
      ],
      "metadata": {
        "id": "UBE6USim-8z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_subsample(images, 'avg', 2)"
      ],
      "metadata": {
        "id": "qe3p08u6-9hR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_subsample(images, 'avg', 3)"
      ],
      "metadata": {
        "id": "F1CeNkyQ_ArB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "train_iterator = data.DataLoader(train_data,\n",
        "                                 shuffle=True,\n",
        "                                 batch_size=BATCH_SIZE)\n",
        "\n",
        "valid_iterator = data.DataLoader(valid_data,\n",
        "                                 batch_size=BATCH_SIZE)\n",
        "\n",
        "test_iterator = data.DataLoader(test_data,\n",
        "                                batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "3GgT7rc3_ICR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
        "            nn.MaxPool2d(2),  # kernel_size\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 192, 3, padding=1),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(192, 384, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, 3, padding=1),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 2 * 2, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, output_dim),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        h = x.view(x.shape[0], -1)\n",
        "        x = self.classifier(h)\n",
        "        return x, h"
      ],
      "metadata": {
        "id": "M57XTakiFAeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIM = 10\n",
        "\n",
        "model = AlexNet(OUTPUT_DIM)"
      ],
      "metadata": {
        "id": "9MBx5MzBFCGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "metadata": {
        "id": "mlP6Fu9xFGMx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}